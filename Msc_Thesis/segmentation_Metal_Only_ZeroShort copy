import cv2
import numpy as np
import matplotlib.pyplot as plt
import tkinter as tk
from tkinter import filedialog, messagebox
from ultralytics import SAM
import torch
import torch.nn.functional as F

# CLIP + PIL will be used for embedding-based zero-shot
import clip
from PIL import Image

# For t-SNE and clustering purely from embeddings
from sklearn.manifold import TSNE
from sklearn.cluster import KMeans


class MetalSegmenter:
    def __init__(self):
        self.image = None
        self.original_image = None
        self.mask = None               # raw segmentation mask (metal = 1)
        self.processed_mask = None     # mask after morphology
        self.model = None              # SAM model
        self.image_path = None
        self.device = "cuda" if torch.cuda.is_available() else "cpu"

        # morphology parameters
        self.kernel_size = 5
        self.erosion_iterations = 1
        self.dilation_iterations = 1

        # rust output
        self.rust_mask = None
        self.rust_percentage = None

        # CLIP model
        self.clip_model = None
        self.clip_preprocess = None

        print(f"Using device: {self.device}")
        self.load_sam2_model()
        self.load_clip_model()

    # ------------------------------------------------------------------
    # MODEL / IMAGE LOADING
    # ------------------------------------------------------------------
    def load_sam2_model(self):
        """Load SAM 2 model from Ultralytics."""
        try:
            print("Loading SAM 2 model...")
            self.model = SAM("sam2.1_b.pt")
            print("SAM 2 model loaded successfully!")
            return True
        except Exception as e:
            print(f"Error loading SAM 2 model: {e}")
            messagebox.showerror("Error", f"Failed to load SAM 2 model: {e}")
            return False

    def load_clip_model(self):
        """Load CLIP model for embedding-based zero-shot detection."""
        try:
            print("Loading CLIP model (ViT-B/32)...")
            self.clip_model, self.clip_preprocess = clip.load(
                "ViT-B/32", device=self.device
            )
            self.clip_model.eval()
            print("CLIP model loaded successfully!")
        except Exception as e:
            print(f"Error loading CLIP model: {e}")
            messagebox.showerror("Error", f"Failed to load CLIP model: {e}")
            self.clip_model = None
            self.clip_preprocess = None

    def load_image(self, image_path=None):
        """Load an image from file (using file dialog if path not given)."""
        if image_path is None:
            root = tk.Tk()
            root.withdraw()
            image_path = filedialog.askopenfilename(
                title="Select metal object image",
                filetypes=[("Image files", "*.jpg *.jpeg *.png *.bmp *.tiff")],
            )
            root.destroy()

        if not image_path:
            return False

        self.image = cv2.imread(image_path)
        if self.image is None:
            messagebox.showerror("Error", "Could not load image!")
            return False

        self.image_path = image_path
        self.original_image = self.image.copy()
        print(f"Image loaded: {self.image.shape}")
        return True

    # ------------------------------------------------------------------
    # BASIC MORPHOLOGY
    # ------------------------------------------------------------------
    def apply_morphological_operations(self, mask):
        """Apply erosion and dilation operations to the mask (internal use)."""
        if mask is None:
            return None

        mask_uint8 = (mask * 255).astype(np.uint8)
        kernel = np.ones((self.kernel_size, self.kernel_size), np.uint8)

        if self.erosion_iterations > 0:
            mask_eroded = cv2.erode(mask_uint8, kernel, iterations=self.erosion_iterations)
        else:
            mask_eroded = mask_uint8.copy()

        if self.dilation_iterations > 0:
            mask_dilated = cv2.dilate(mask_eroded, kernel, iterations=self.dilation_iterations)
        else:
            mask_dilated = mask_eroded.copy()

        processed_mask = (mask_dilated > 127).astype(np.uint8)
        return processed_mask

    # ------------------------------------------------------------------
    # NEW: PATCH EMBEDDING EXTRACTION (NO TEXT EMBEDDINGS HERE)
    # ------------------------------------------------------------------
    def extract_patch_embeddings(
        self,
        patch_size=224,
        stride=112,
        min_metal_ratio=0.3,
        max_patches=500
    ):
        """
        Extract CLIP embeddings of patches from the metal region only.

        This is purely image-embedding-based (NO text embeddings).
        Returns:
            embeddings_np: (N, D) numpy array
            centers: list/array of (x_center, y_center) for each patch
        """
        if self.clip_model is None or self.clip_preprocess is None:
            print("CLIP model not available for patch embedding extraction.")
            return None, None

        if self.original_image is None:
            print("No image loaded for patch embedding extraction.")
            return None, None

        metal_mask = self.processed_mask if self.processed_mask is not None else self.mask
        if metal_mask is None:
            print("No metal mask available for patch embedding extraction.")
            return None, None

        metal_mask = (metal_mask > 0).astype(np.uint8)
        img_bgr = self.original_image
        H_img, W_img = metal_mask.shape

        ys, xs = np.where(metal_mask == 1)
        if len(xs) == 0:
            print("No metal pixels found for patch embedding extraction.")
            return None, None

        # bounding box over metal region
        ymin, ymax = ys.min(), ys.max()
        xmin, xmax = xs.min(), xs.max()

        embeddings = []
        centers = []

        print("Extracting patch embeddings (purely image-based)...")
        with torch.no_grad():
            for y in range(ymin, ymax + 1, stride):
                for x in range(xmin, xmax + 1, stride):
                    y2 = min(y + patch_size, H_img)
                    x2 = min(x + patch_size, W_img)

                    patch_mask = metal_mask[y:y2, x:x2]
                    if patch_mask.size == 0:
                        continue

                    # ensure the patch is mostly metal
                    if patch_mask.sum() < min_metal_ratio * patch_mask.size:
                        continue

                    patch_bgr = img_bgr[y:y2, x:x2]
                    patch_rgb = cv2.cvtColor(patch_bgr, cv2.COLOR_BGR2RGB)
                    pil_img = Image.fromarray(patch_rgb)

                    img_input = self.clip_preprocess(pil_img).unsqueeze(0).to(self.device)
                    img_feat = self.clip_model.encode_image(img_input)
                    img_feat = F.normalize(img_feat, dim=-1)  # [1, D]

                    embeddings.append(img_feat.squeeze(0).cpu().numpy())
                    # store patch center for visualization
                    cx = (x + x2) // 2
                    cy = (y + y2) // 2
                    centers.append((cx, cy))

        if len(embeddings) == 0:
            print("No valid patches found for embedding extraction.")
            return None, None

        embeddings = np.array(embeddings)  # (N, D)
        centers = np.array(centers)        # (N, 2)

        # Optional: random subsample if too many patches for t-SNE
        if max_patches is not None and embeddings.shape[0] > max_patches:
            print(f"Subsampling patches from {embeddings.shape[0]} to {max_patches} for t-SNE...")
            idx = np.random.choice(embeddings.shape[0], size=max_patches, replace=False)
            embeddings = embeddings[idx]
            centers = centers[idx]

        print(f"Total patches used for analysis: {embeddings.shape[0]}")
        return embeddings, centers

    # ------------------------------------------------------------------
    # NEW: T-SNE VISUALIZATION USING ONLY PATCH EMBEDDINGS
    # ------------------------------------------------------------------
    def visualize_tsne_clusters(self, embeddings, centers, n_clusters=2):
        """
        Run t-SNE on patch embeddings and visualize:
          - 2D t-SNE scatter plot (colored by KMeans clusters)
          - cluster positions on the original image

        This uses ONLY patch embeddings, NO text embeddings.
        """
        if embeddings is None or centers is None:
            print("No embeddings or centers provided for t-SNE visualization.")
            return

        n_samples = embeddings.shape[0]
        if n_samples < 3:
            print(f"Not enough samples for t-SNE (got {n_samples}, need >= 3).")
            return

        # ---- ADAPTIVE PERPLEXITY TO AVOID ERROR ----
        # t-SNE requires: 1 <= perplexity < n_samples
        base_perplexity = 30.0
        # keep perplexity comfortably below n_samples
        perplexity = min(base_perplexity, (n_samples - 1) / 3.0)
        perplexity = max(5.0, perplexity)   # at least 5 for stability
        if perplexity >= n_samples:
            perplexity = n_samples - 1e-4   # just in case for very small n

        print(f"Running KMeans clustering on {n_samples} embeddings...")
        kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
        cluster_labels = kmeans.fit_predict(embeddings)

        print(f"Running t-SNE projection (2D) with perplexity={perplexity:.2f} ...")
        tsne = TSNE(
            n_components=2,
            perplexity=perplexity,
            learning_rate='auto',
            init='random',
            random_state=42
        )
        embeddings_2d = tsne.fit_transform(embeddings)  # (N, 2)

        img_rgb = cv2.cvtColor(self.original_image, cv2.COLOR_BGR2RGB)

        # Plot t-SNE + cluster overlay on image
        fig, axes = plt.subplots(1, 2, figsize=(14, 6))
        fig.suptitle("Patch Embedding Structure (Image-based CLIP Embeddings)",
                     fontsize=16, fontweight="bold")

        # 1) t-SNE scatter
        ax0 = axes[0]
        scatter = ax0.scatter(
            embeddings_2d[:, 0],
            embeddings_2d[:, 1],
            c=cluster_labels,
            cmap="tab10",
            s=20,
            alpha=0.8
        )
        ax0.set_title("t-SNE of Patch Embeddings\nColor = Unsupervised Clusters (KMeans)")
        ax0.set_xlabel("t-SNE 1")
        ax0.set_ylabel("t-SNE 2")
        legend1 = ax0.legend(
            *scatter.legend_elements(),
            title="Clusters",
            loc="best"
        )
        ax0.add_artist(legend1)

        # 2) Original image with patch centers colored by cluster
        ax1 = axes[1]
        ax1.imshow(img_rgb)
        ax1.set_title("Patch Locations Colored by Embedding Cluster")
        ax1.axis("off")

        for (cx, cy), label in zip(centers, cluster_labels):
            ax1.scatter(cx, cy, c=[plt.cm.tab10(label)], s=35,
                        edgecolors="black", linewidths=0.5)

        plt.tight_layout()
        plt.show()

        print("t-SNE + clustering visualization completed.")
        print("Interpretation idea:")
        print("  - If clusters roughly correspond to rusted vs non-rusted patches,")
        print("    CLIP embeddings contain useful structure for your two classes.")

    def analyze_embedding_structure(self):
        """
        Full pipeline for the supervisor's request:

        - Select an image (done in run())
        - Extract patches from metal region
        - Compute CLIP embeddings (image only)
        - Visualize with t-SNE and clustering
        """
        if self.original_image is None:
            print("No image loaded; cannot analyze embedding structure.")
            return

        if self.processed_mask is None and self.mask is not None:
            self.processed_mask = self.apply_morphological_operations(self.mask)

        if self.processed_mask is None:
            print("No metal mask available; cannot restrict patches to metal.")
            return

        embeddings, centers = self.extract_patch_embeddings(
            patch_size=224,    # relatively large patches for CLIP
            stride=112,        # overlap
            min_metal_ratio=0.3,
            max_patches=500    # limit for t-SNE
        )

        if embeddings is not None and centers is not None:
            self.visualize_tsne_clusters(embeddings, centers)
        else:
            print("Embedding structure analysis skipped (no valid embeddings).")

    # ------------------------------------------------------------------
    # EMBEDDING-BASED ZERO-SHOT RUST DETECTOR (CLIP) - original logic
    # ------------------------------------------------------------------
    def rust_clip_embedding_based(self, patch_size=64, stride=32):
        """
        Embedding-based zero-shot rust detector using CLIP.

        NOTE: This still uses text embeddings to compare
        "rusted metal" vs "clean metal", but this is for your
        rust-percentage estimation, not for the embedding structure test.
        """
        if self.clip_model is None or self.clip_preprocess is None:
            print("CLIP model not available.")
            return np.zeros_like(self.processed_mask, dtype=np.uint8), 0.0

        if self.original_image is None:
            print("No image loaded for rust detection.")
            return np.zeros_like(self.processed_mask, dtype=np.uint8), 0.0

        metal_mask = self.processed_mask if self.processed_mask is not None else self.mask
        if metal_mask is None:
            print("No metal mask available for rust detection.")
            return np.zeros_like(self.processed_mask, dtype=np.uint8), 0.0

        metal_mask = (metal_mask > 0).astype(np.uint8)
        img_bgr = self.original_image
        H_img, W_img = metal_mask.shape

        ys, xs = np.where(metal_mask == 1)
        if len(xs) == 0:
            print("No metal pixels found.")
            return np.zeros_like(metal_mask, dtype=np.uint8), 0.0

        # Prepare text embeddings
        with torch.no_grad():
            text = clip.tokenize(
                ["a close-up photo of rusted metal surface",
                 "a close-up photo of clean shiny metal surface"]
            ).to(self.device)
            text_features = self.clip_model.encode_text(text)
            text_features = F.normalize(text_features, dim=-1)  # [2, D]

        # Rust mask to fill
        rust_mask = np.zeros_like(metal_mask, dtype=np.uint8)

        # Bounding box of metal region to limit scanning
        ymin, ymax = ys.min(), ys.max()
        xmin, xmax = xs.min(), xs.max()

        print("Running CLIP-based zero-shot rust detection...")
        for y in range(ymin, ymax + 1, stride):
            for x in range(xmin, xmax + 1, stride):
                y2 = min(y + patch_size, H_img)
                x2 = min(x + patch_size, W_img)

                patch_mask = metal_mask[y:y2, x:x2]
                # Skip patch if almost no metal
                if patch_mask.sum() < 0.3 * patch_mask.size:
                    continue

                patch_bgr = img_bgr[y:y2, x:x2]
                patch_rgb = cv2.cvtColor(patch_bgr, cv2.COLOR_BGR2RGB)
                pil_img = Image.fromarray(patch_rgb)

                with torch.no_grad():
                    img_input = self.clip_preprocess(pil_img).unsqueeze(0).to(self.device)
                    img_feat = self.clip_model.encode_image(img_input)
                    img_feat = F.normalize(img_feat, dim=-1)  # [1, D]

                    sims = (img_feat @ text_features.T).squeeze(0)  # [2]
                    rust_sim = sims[0].item()
                    clean_sim = sims[1].item()

                if rust_sim > clean_sim:
                    rust_mask[y:y2, x:x2] = 1

        # Only count rust inside metal region
        rust_mask = rust_mask * metal_mask

        rust_pixels = rust_mask.sum()
        metal_pixels = metal_mask.sum()
        rust_percentage = (rust_pixels / metal_pixels * 100.0) if metal_pixels > 0 else 0.0

        return rust_mask.astype(np.uint8), rust_percentage

    def run_rust_detection(self):
        """Run embedding-based CLIP zero-shot detector on metal region."""
        if self.original_image is None:
            print("No image loaded; cannot run rust detection.")
            return
        if self.processed_mask is None and self.mask is None:
            print("No mask available; run segmentation first.")
            return

        self.rust_mask, self.rust_percentage = self.rust_clip_embedding_based()

        if self.rust_mask is not None:
            self.show_rust_results()
        else:
            print("Rust detection failed or skipped.")

    def show_rust_results(self):
        """Show ONLY the final 3-panel rust figure."""
        if self.rust_mask is None:
            print("No rust mask to display.")
            return

        img_rgb = cv2.cvtColor(self.original_image, cv2.COLOR_BGR2RGB)
        metal_mask = self.processed_mask if self.processed_mask is not None else self.mask
        metal_mask = (metal_mask > 0).astype(np.uint8)

        fig, axes = plt.subplots(1, 3, figsize=(16, 5))
        fig.suptitle("Embedding-Based Zero-Shot Rust Detection (CLIP)",
                     fontsize=16, fontweight="bold")

        # 1) Original image
        axes[0].imshow(img_rgb)
        axes[0].set_title("Original Image", fontweight="bold")
        axes[0].axis("off")

        # 2) Metal-only region
        metal_only = img_rgb.copy()
        metal_only[metal_mask == 0] = 0
        axes[1].imshow(metal_only)
        axes[1].set_title("Metal Region", fontweight="bold")
        axes[1].axis("off")

        # 3) Rust overlay ON METAL REGION ONLY
        base = metal_only.copy()
        overlay = base.copy()
        overlay[self.rust_mask == 1] = [255, 0, 0]   # red rust on metal
        blended = cv2.addWeighted(base, 0.7, overlay, 0.3, 0)

        title = "Rust Areas (Red)"
        if self.rust_percentage is not None:
            title += f"\nEstimated Corrosion: {self.rust_percentage:.2f}% of metal"
        axes[2].imshow(blended)
        axes[2].set_title(title, fontweight="bold")
        axes[2].axis("off")

        plt.tight_layout()
        plt.show()

        if self.rust_percentage is not None:
            print(f"Estimated rust / corrosion: {self.rust_percentage:.2f}% of metal region.")

    # ------------------------------------------------------------------
    # SEGMENTATION PIPELINE
    # ------------------------------------------------------------------
    def detect_metal_regions(self):
        """Automatically detect metal-like regions based on visual properties."""
        if self.image is None:
            return []
        try:
            gray = cv2.cvtColor(self.image, cv2.COLOR_BGR2GRAY)
            hsv = cv2.cvtColor(self.image, cv2.COLOR_BGR2HSV)
            lab = cv2.cvtColor(self.image, cv2.COLOR_BGR2LAB)

            blurred = cv2.GaussianBlur(gray, (5, 5), 0)
            edges = cv2.Canny(blurred, 50, 150)

            _, A, _ = cv2.split(lab)
            metal_mask1 = cv2.inRange(A, 120, 135)

            _, S, V = cv2.split(hsv)
            metal_mask2 = cv2.inRange(S, 30, 100) & cv2.inRange(V, 100, 255)

            kernel = np.ones((3, 3), np.uint8)
            edges_dilated = cv2.dilate(edges, kernel, iterations=2)

            combined_metal = cv2.bitwise_or(metal_mask1, metal_mask2)
            combined_metal = cv2.bitwise_or(combined_metal, edges_dilated)
            combined_metal = cv2.morphologyEx(combined_metal, cv2.MORPH_CLOSE, kernel)
            combined_metal = cv2.morphologyEx(combined_metal, cv2.MORPH_OPEN, kernel)

            contours, _ = cv2.findContours(combined_metal, cv2.RETR_EXTERNAL,
                                           cv2.CHAIN_APPROX_SIMPLE)

            regions = []
            min_area = 500
            for contour in contours:
                area = cv2.contourArea(contour)
                if area > min_area:
                    x, y, w, h = cv2.boundingRect(contour)
                    center_x = x + w // 2
                    center_y = y + h // 2
                    regions.append(
                        {
                            "id": len(regions),
                            "bbox": [x, y, x + w, y + h],
                            "center": [center_x, center_y],
                            "area": area,
                        }
                    )
            return regions
        except Exception as e:
            print(f"Metal detection error: {e}")
            return []

    def sam2_predict(self, points, labels):
        """Predict segmentation mask using SAM 2, then apply morphology."""
        if self.model is None:
            messagebox.showerror("Error", "SAM 2 model not loaded!")
            return None
        try:
            image_rgb = cv2.cvtColor(self.original_image, cv2.COLOR_BGR2RGB)
            results = self.model.predict(image_rgb, points=points, labels=labels)
            if (
                results
                and len(results) > 0
                and results[0].masks is not None
                and len(results[0].masks.data) > 0
            ):
                mask = results[0].masks.data[0].cpu().numpy()
                binary_mask = (mask > 0.5).astype(np.uint8)
                self.processed_mask = self.apply_morphological_operations(binary_mask)
                return binary_mask
            return None
        except Exception as e:
            print(f"SAM 2 prediction error: {e}")
            return self.fallback_segmentation(points, labels)

    def fallback_segmentation(self, points, labels):
        """Fallback segmentation using GrabCut if SAM fails."""
        if len(points) == 0:
            mask = np.zeros(self.original_image.shape[:2], dtype=np.uint8)
            self.processed_mask = mask.copy()
            return mask

        mask = np.zeros(self.original_image.shape[:2], dtype=np.uint8)
        for point, label in zip(points, labels):
            x, y = point
            if label == 1:  # foreground
                cv2.circle(mask, (x, y), 15, 3, -1)
            else:  # background
                cv2.circle(mask, (x, y), 15, 0, -1)

        bgd_model = np.zeros((1, 65), np.float64)
        fgd_model = np.zeros((1, 65), np.float64)

        if any(l == 1 for l in labels):
            fg_points = [points[i] for i in range(len(points)) if labels[i] == 1]
            x_coords = [p[0] for p in fg_points]
            y_coords = [p[1] for p in fg_points]
            x1 = max(0, min(x_coords) - 30)
            x2 = min(self.image.shape[1], max(x_coords) + 30)
            y1 = max(0, min(y_coords) - 30)
            y2 = min(self.image.shape[0], max(y_coords) + 30)
            rect = (x1, y1, x2 - x1, y2 - y1)

            cv2.grabCut(
                self.original_image,
                mask,
                rect,
                bgd_model,
                fgd_model,
                5,
                cv2.GC_INIT_WITH_RECT,
            )

        final_mask = np.where((mask == 2) | (mask == 0), 0, 1).astype(np.uint8)
        self.processed_mask = self.apply_morphological_operations(final_mask)
        return final_mask

    def interactive_metal_segmentation(self):
        """Main interactive segmentation for metal objects."""
        if self.image is None:
            messagebox.showerror("Error", "Please load an image first!")
            return False

        print("Detecting metal regions...")
        regions = self.detect_metal_regions()
        if regions:
            print(
                f"Found {len(regions)} potential metal regions - using auto-detection mode"
            )
            return self.auto_detection_mode(regions)
        else:
            print("No metal regions auto-detected - using manual point mode")
            return self.manual_point_mode()

    def auto_detection_mode(self, regions):
        """Auto-detection mode where user clicks on detected metal regions."""
        cv2.namedWindow("Click on METAL Parts - Press 's' when done")

        def click_callback(event, x, y, flags, param):
            regions_param = param["regions"]
            if event == cv2.EVENT_LBUTTONDOWN:
                for region in regions_param:
                    x1, y1, x2, y2 = map(int, region["bbox"])
                    if x1 <= x <= x2 and y1 <= y <= y2:
                        print(f"Selected metal region {region['id']}")
                        center_x, center_y = region["center"]
                        self.mask = self.sam2_predict(
                            points=[[center_x, center_y]], labels=[1]
                        )
                        self.update_auto_display(regions_param, region["id"])
                        break

        self.update_auto_display(regions, -1)
        param = {"regions": regions}
        cv2.setMouseCallback(
            "Click on METAL Parts - Press 's' when done", click_callback, param
        )

        while True:
            key = cv2.waitKey(1) & 0xFF
            if key == ord("m"):
                cv2.destroyAllWindows()
                return self.manual_point_mode()
            elif key == ord("s"):
                if self.mask is not None and np.any(self.mask):
                    cv2.destroyAllWindows()
                    return True
                else:
                    messagebox.showwarning(
                        "No Selection", "Please select a metal region first!"
                    )
            elif key == ord("q"):
                cv2.destroyAllWindows()
                return False

    def update_auto_display(self, regions, selected_id):
        """Update display for auto-detection mode (OpenCV only)."""
        display_image = self.original_image.copy()
        for region in regions:
            x1, y1, x2, y2 = map(int, region["bbox"])
            center_x, center_y = map(int, region["center"])
            if region["id"] == selected_id:
                color = (0, 255, 0)
                thickness = 3
                if self.mask is not None and np.any(self.mask):
                    overlay = display_image.copy()
                    overlay[self.mask == 1] = [0, 255, 0]
                    display_image = cv2.addWeighted(
                        display_image, 0.7, overlay, 0.3, 0
                    )
            else:
                color = (255, 0, 0)
                thickness = 2

            cv2.rectangle(display_image, (x1, y1), (x2, y2), color, thickness)
            cv2.putText(
                display_image,
                f"M{region['id']}",
                (center_x, center_y),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.8,
                (255, 255, 255),
                3,
            )
            cv2.putText(
                display_image,
                f"M{region['id']}",
                (center_x, center_y),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.8,
                color,
                2,
            )

        instructions = [
            "METAL DETECTION MODE",
            f"Found {len(regions)} potential metal regions",
            "Click on any METAL REGION (M0, M1, etc.) to select it",
            "Green = Selected metal, Blue = Potential metal",
            "Press 'm' for manual mode, 's' to save selection, 'q' to quit",
        ]
        for i, instruction in enumerate(instructions):
            cv2.putText(
                display_image,
                instruction,
                (10, 30 + i * 25),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.6,
                (0, 0, 0),
                3,
            )
            cv2.putText(
                display_image,
                instruction,
                (10, 30 + i * 25),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.6,
                (255, 255, 255),
                1,
            )

        cv2.imshow("Click on METAL Parts - Press 's' when done", display_image)

    def manual_point_mode(self):
        """Manual point-based segmentation for metal objects."""
        print("Manual metal segmentation mode")
        cv2.namedWindow("Click on METAL Objects - Press 's' when done")
        points, labels = [], []

        def click_callback(event, x, y, flags, param):
            if event == cv2.EVENT_LBUTTONDOWN:
                points.append([x, y])
                labels.append(1)
                print(f"Added metal point at ({x}, {y})")
                self.mask = self.sam2_predict(points, labels)
                self.update_manual_display(points)

        cv2.setMouseCallback(
            "Click on METAL Objects - Press 's' when done", click_callback
        )
        self.update_manual_display(points)

        while True:
            key = cv2.waitKey(1) & 0xFF
            if key == ord("c"):
                points.clear()
                labels.clear()
                self.mask = np.zeros(self.image.shape[:2], dtype=np.uint8)
                self.processed_mask = np.zeros(self.image.shape[:2], dtype=np.uint8)
                self.update_manual_display(points)
                print("Cleared all points")
            elif key == ord("s"):
                if points:
                    cv2.destroyAllWindows()
                    return True
                else:
                    messagebox.showwarning(
                        "No Points", "Please click on metal areas first!"
                    )
            elif key == ord("q"):
                cv2.destroyAllWindows()
                return False

    def update_manual_display(self, points):
        """Update display for manual point mode (OpenCV only)."""
        display_image = self.original_image.copy()
        for x, y in points:
            cv2.circle(display_image, (x, y), 8, (0, 255, 0), -1)
            cv2.circle(display_image, (x, y), 10, (255, 255, 255), 2)

        if self.mask is not None and np.any(self.mask):
            overlay = display_image.copy()
            overlay[self.mask == 1] = [0, 255, 0]
            display_image = cv2.addWeighted(display_image, 0.7, overlay, 0.3, 0)

        instructions = [
            "MANUAL METAL SEGMENTATION",
            "Click on METAL objects to segment them",
            "Green circles = Your clicks, Green overlay = Detected metal",
            "Press 'c' to clear points, 's' to save selection, 'q' to quit",
        ]
        for i, instruction in enumerate(instructions):
            cv2.putText(
                display_image,
                instruction,
                (10, 30 + i * 25),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.6,
                (0, 0, 0),
                3,
            )
            cv2.putText(
                display_image,
                instruction,
                (10, 30 + i * 25),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.6,
                (255, 255, 255),
                1,
            )

        cv2.imshow("Click on METAL Objects - Press 's' when done", display_image)

    # ------------------------------------------------------------------
    # FINAL STEP WRAPPERS
    # ------------------------------------------------------------------
    def show_results(self):
        """Run embedding-based rust detection and show the final figure."""
        if self.image is None or self.mask is None:
            messagebox.showwarning("No Results", "No segmentation results to display.")
            return

        if self.processed_mask is None:
            self.processed_mask = self.apply_morphological_operations(self.mask)

        self.run_rust_detection()

    def run(self):
        print("METAL SEGMENTATION + CLIP EMBEDDINGS + t-SNE STRUCTURE ANALYSIS")
        print("=" * 80)
        if not self.load_image():
            return
        if not self.interactive_metal_segmentation():
            return

        # 1) Analyze embedding structure (t-SNE & clusters) - PURELY IMAGE EMBEDDINGS
        self.analyze_embedding_structure()

        # 2) (Optional) Run your original rust detection pipeline
        self.show_results()
        print("Segmentation, embedding-structure analysis, and rust estimation completed.")


if __name__ == "__main__":
    segmenter = MetalSegmenter()
    segmenter.run()
